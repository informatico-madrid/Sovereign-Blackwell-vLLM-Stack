model_list:
  - model_name: ${SERVED_MODEL_NAME}
    litellm_params:
      model: openai/${SERVED_MODEL_NAME}
      api_base: http://vllm-engine:8000/v1
      api_key: sk-1234 # Key interna LiteLLM y vLLM
      drop_params: True
      enable_tool_calling: True
      stream: true
      # recomended params for Qwen3-Coder
      temperature: 0.7
      top_p: 0.8
      top_k: 20
      repetition_penalty: 1.05
    model_info:
      # Tool calling metadata
      supports_function_calling: true
      supports_parallel_function_calling: true

litellm_settings:
  drop_params: True
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]